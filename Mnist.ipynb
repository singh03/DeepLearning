{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: # Only use this if using iPython\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline # Only use this if using iPython\n",
    "image_index = 7777 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 44s 737us/step - loss: 0.2016 - acc: 0.9397\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 42s 702us/step - loss: 0.0824 - acc: 0.9745\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 50s 826us/step - loss: 0.0577 - acc: 0.9812\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 44s 735us/step - loss: 0.0442 - acc: 0.9848\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 48s 802us/step - loss: 0.0350 - acc: 0.9887\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 47s 778us/step - loss: 0.0296 - acc: 0.9899\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 44s 734us/step - loss: 0.0243 - acc: 0.9915\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 47s 789us/step - loss: 0.0224 - acc: 0.9923\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 50s 826us/step - loss: 0.0206 - acc: 0.9929\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 44s 740us/step - loss: 0.0178 - acc: 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab33f29518>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 229us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07570138302151609, 0.9836]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8be3f3309b74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimage_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4444\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Greys'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_rows' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 4444\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, img_rows, img_cols, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
